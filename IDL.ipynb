{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc773f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "643ecb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d76b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 1]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Forward Propagation\n",
    "input_data =  np.array([2,3])\n",
    "weights ={'node_0': np.array([1,1]), 'node_1':np.array([-1,1]), 'output': np.array([2,-1])}\n",
    "node_0_value = (input_data * weights['node_0']).sum()\n",
    "node_1_value = (input_data * weights['node_1']).sum()\n",
    "\n",
    "hidden_layer_values = np.array([node_0_value,node_1_value])\n",
    "print(hidden_layer_values)\n",
    "\n",
    "output = (hidden_layer_values * weights['output']).sum()\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cea591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9901095378334199\n"
     ]
    }
   ],
   "source": [
    "# Activation Function\n",
    "#allows the hidden layers to capture non-linearity\n",
    "\n",
    "input_data =  np.array([-1,2])\n",
    "weights ={'node_0': np.array([3,3]), 'node_1':np.array([1,5]), 'output': np.array([2,-1])}\n",
    "node_0_input = (input_data * weights['node_0']).sum()\n",
    "node_0_output = np.tanh(node_0_input)\n",
    "\n",
    "node_1_input = (input_data * weights['node_1']).sum()\n",
    "node_1_output = np.tanh(node_1_input)\n",
    "\n",
    "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "output = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57964da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3\n"
     ]
    }
   ],
   "source": [
    "# ReLU - rectified linear activation\n",
    "# 0 if x<0 and x if x>=0\n",
    "\n",
    "def relu(input):\n",
    "    output = max(0, input)\n",
    "    return(output)\n",
    "\n",
    "node_0_input = (input_data * weights['node_0']).sum()\n",
    "node_0_output = relu(node_0_input)\n",
    "\n",
    "node_1_input = (input_data * weights['node_1']).sum()\n",
    "node_1_output = relu(node_1_input)\n",
    "\n",
    "hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "\n",
    "model_output = (hidden_layer_outputs * weights['output']).sum()\n",
    "\n",
    "print(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9decec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_network_1(input_data_row, weights):\n",
    "    node_0_input = (input_data_row * weights['node_0']).sum() \n",
    "    node_0_output = relu(node_0_input)\n",
    "    \n",
    "    node_1_input = (input_data_row * weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "    \n",
    "    hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "    \n",
    "    input_to_final_layer = (hidden_layer_outputs * weights['output']).sum()\n",
    "    model_output = relu(input_to_final_layer)\n",
    "    \n",
    "    return(model_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97edb9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52, 63, 0, 148]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "input_data = [np.array([3,5]),np.array([1,-1]),np.array([0,0]),np.array([8,4])]\n",
    "weights = {'node_0': np.array([2, 4]), 'node_1': np.array([ 4, -5]), 'output': np.array([2, 7])}\n",
    "\n",
    "for input_data_row in input_data:\n",
    "    results.append(predict_with_network_1(input_data_row, weights))\n",
    "    \n",
    "print(results)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effe7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeper Networks - Multiple hidden layers\n",
    "# internally build representations of patterns in the data\n",
    "# partially replace the need for feature engineering\n",
    "# subsequent layers build increasingly sophisticated representations of raw data\n",
    "\n",
    "# Modeler doesn't need to specify the interactions\n",
    "# when the model is trained, the neural network gets weights that find relevant patterns to make better predictions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0630ff52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "weights = {'node_0_0': np.array([2, 4]), 'node_0_1': np.array([ 4, -5]), 'node_1_0': np.array([-1,  2]), 'node_1_1': np.array([1, 2]), 'output': np.array([2, 7])}\n",
    "\n",
    "\n",
    "def predict_with_network(input_data):\n",
    "    # Calculate node 0 in the first hidden layer\n",
    "    node_0_0_input = (input_data * weights['node_0_0']).sum()\n",
    "    node_0_0_output = relu(node_0_0_input)\n",
    "\n",
    "    # Calculate node 1 in the first hidden layer\n",
    "    node_0_1_input = (input_data * weights['node_0_1']).sum()\n",
    "    node_0_1_output = relu(node_0_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_0_outputs\n",
    "    hidden_0_outputs = np.array([node_0_0_output, node_0_1_output])\n",
    "\n",
    "    # Calculate node 0 in the second hidden layer\n",
    "    node_1_0_input = (hidden_0_outputs * weights['node_1_0']).sum()\n",
    "    node_1_0_output = relu(node_1_0_input)\n",
    "\n",
    "    # Calculate node 1 in the second hidden layer\n",
    "    node_1_1_input = (hidden_0_outputs * weights['node_1_1']).sum()\n",
    "    node_1_1_output = relu(node_1_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_1_outputs\n",
    "    hidden_1_outputs = np.array([node_1_0_output, node_1_1_output])\n",
    "    \n",
    "    # Calculate output here: model_output\n",
    "    model_output = (hidden_1_outputs * weights['output']).sum()\n",
    "    \n",
    "    # Return model_output\n",
    "    return(model_output)\n",
    "\n",
    "input_data = np.array([3,5])\n",
    "output = predict_with_network(input_data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a68d1f",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a0fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function aggregates errors in predictions from data points into single number\n",
    "# it predicts model's predictive performance\n",
    "# common loss function is MSE\n",
    "# lower loss - better model\n",
    "# goal - finding weights that give the lowest value for the loss function\n",
    "# this is done using an algorithm called \"Gradient descent\"\n",
    "\n",
    "# \"How Gradient Descent works\"\n",
    "# 1. Start at a random point\n",
    "# 2. Until you rae somewhat flat, \n",
    "    # find the slope\n",
    "    # take a step downhill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16f4c31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "input_data = np.array([0, 3])\n",
    "\n",
    "weights_0 = {'node_0': [2, 1],'node_1': [1, 2],'output': [1, 1]}\n",
    "\n",
    "target_actual = 3\n",
    "\n",
    "model_output_0 = predict_with_network_1(input_data, weights_0)\n",
    "\n",
    "error_0 = model_output_0 - target_actual\n",
    "\n",
    "weights_1 = {'node_0': [2, 1],\n",
    "             'node_1': [1, 0],\n",
    "             'output': [1, 1]\n",
    "            }\n",
    "\n",
    "model_output_1 = predict_with_network_1(input_data, weights_1)\n",
    "\n",
    "error_1 = target_actual - model_output_1\n",
    "\n",
    "print(error_0)\n",
    "print(error_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "510b8dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error with weights_0: 37.500000\n",
      "Mean squared error with weights_1: 49.890625\n"
     ]
    }
   ],
   "source": [
    "target_actuals = np.array([1, 3, 5, 7])\n",
    "weights_0 = {'node_0': np.array([2, 1]), 'node_1': np.array([1, 2]), 'output': np.array([1, 1])}\n",
    "weights_1 = {'node_0': np.array([2, 1]), 'node_1': np.array([1. , 1.5]), 'output': np.array([1. , 1.5])}\n",
    "input_data = [np.array([0, 3]), np.array([1, 2]), np.array([-1, -2]), np.array([4, 0])]\n",
    "\n",
    "model_output_0 = []\n",
    "model_output_1 = []\n",
    "\n",
    "for row in input_data:\n",
    "    # Append prediction to model_output_0\n",
    "    model_output_0.append(predict_with_network_1(row,weights_0 ))\n",
    "    \n",
    "    # Append prediction to model_output_1\n",
    "    model_output_1.append(predict_with_network_1(row,weights_1 ))\n",
    "    \n",
    "\n",
    "mse_0 = mean_squared_error(target_actuals, model_output_0)\n",
    "\n",
    "mse_1 = mean_squared_error(target_actuals, model_output_1)\n",
    "\n",
    "# Print mse_0 and mse_1\n",
    "print(\"Mean squared error with weights_0: %f\" %mse_0)\n",
    "print(\"Mean squared error with weights_1: %f\" %mse_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "564d41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent\n",
    "# if slope is positive, going opposite the slope - moving to lower numbers\n",
    "# subtract the slope from the current value\n",
    "# too big a step might lead us astray\n",
    "\n",
    "# instead of subtracting the slope, we multiply it by a small number called 'learning rate'\n",
    "# then update each weight by subtracting learning rate * slope\n",
    "\n",
    "# Slope calculation Eg\n",
    "# 3-----2----->6  ;  3 & 6 nodes ; 2 - weight; actual target =10 \n",
    "# To calculate the slope for a weight, need to multiply 3 things\n",
    "#     slope of loss fun wrt value at node we feed into(the model's prediction)\n",
    "#         2(Predicted value - Actual Value) = 2 (6 - 10) = -8\n",
    "#     value at the node that feeds into our weight\n",
    "#         3\n",
    "#     slope of activation fun wrt value we feed into\n",
    "#         we don't have activation function in this case\n",
    "\n",
    "# Multiplying the three(two) -> -8 * 3 = -24(slope of the loss)\n",
    "# If learning rate = 0.01; new weight would be 2-(0.01 * -24 ) = 2.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94b5be81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Network with two inputs affecting prediction\n",
    "\n",
    "# 3 & 4 - nodes; 1 & 2 - weights \n",
    "\n",
    "# 3\n",
    "#  * \n",
    "#   1\n",
    "#    *\n",
    "#     *\n",
    "#    *\n",
    "#   2\n",
    "#  *  \n",
    "# 4\n",
    "\n",
    "weights = np.array([1,2])\n",
    "input_data = np.array([3,4])\n",
    "target = 6\n",
    "learning_rate = 0.01\n",
    "preds = (weights * input_data).sum()\n",
    "error = preds- target\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b1388f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30 40]\n"
     ]
    }
   ],
   "source": [
    "gradient = 2 * input_data*error\n",
    "print(gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf414113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n"
     ]
    }
   ],
   "source": [
    "weights_updated = weights - learning_rate * gradient\n",
    "preds_updated = (weights_updated * input_data).sum()\n",
    "error_updated = preds_updated - target\n",
    "print(error_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0f9ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope :  [14 28 42]\n",
      "error :  7\n",
      "error_updated :  5.04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weights = np.array([0,2,1])\n",
    "input_data = np.array([1,2,3])\n",
    "target = 0\n",
    "\n",
    "preds = (weights * input_data).sum()\n",
    "error = preds - target\n",
    "slope = 2 * input_data * error\n",
    "\n",
    "print(\"Slope : \",slope)\n",
    "\n",
    "learning_rate = 0.01\n",
    "weights_updated = weights - learning_rate*slope\n",
    "preds_updated = (weights_updated * input_data).sum()\n",
    "error_updated = preds_updated - target\n",
    "\n",
    "print(\"error : \",error)\n",
    "print(\"error_updated : \",error_updated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e432e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Making multiple updates to weights\n",
    "# n_updates = 20\n",
    "# mse_hist = []\n",
    "\n",
    "# def get_slope(input_data, target, weights):\n",
    "#     preds = (weights * input_data).sum()\n",
    "#     error = preds - target\n",
    "#     slope = 2 * input_data * error\n",
    "#     return slope\n",
    "\n",
    "# def get_mse(input_data, target, weights):\n",
    "# #     model_output = []\n",
    "# #     for row in input_data:\n",
    "# #         model_output.append(predict_with_network_1(row,weights))\n",
    "#     model_output = (input_data*weights).sum()\n",
    "#     mse = mean_squared_error(target, model_output)\n",
    "#     return mse\n",
    "    \n",
    "\n",
    "# n_updates = 20\n",
    "# mse_hist = []\n",
    "\n",
    "# # Iterate over the number of updates\n",
    "# for i in range(n_updates):\n",
    "#     # Calculate the slope: slope\n",
    "#     slope = get_slope(input_data, target, weights)\n",
    "    \n",
    "#     # Update the weights: weights\n",
    "#     weights = weights - slope * 0.01\n",
    "    \n",
    "#     # Calculate mse with new weights: mse\n",
    "#     mse = get_mse(input_data, target, weights)\n",
    "    \n",
    "#     # Append the mse to mse_hist\n",
    "#     mse_hist.append(mse)\n",
    "\n",
    "# # Plot the mse history\n",
    "# plt.plot(mse_hist)\n",
    "# plt.xlabel('Iterations')\n",
    "# plt.ylabel('Mean Squared Error')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e1fed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "# takes the error from the o/p layer and propagates it backwards through the hidden layerstowards the input layer\n",
    "\n",
    "# allows gradient descent to update all weights in neural network (by getting gradients for all weights)\n",
    "# comes from chain rule of calculus\n",
    "\n",
    "# we are trying to estimate the slope of the loss function w.r.t each weight\n",
    "# Do fwd propagation to calculate predictions nad errors before we do back propagation\n",
    "\n",
    "# In back propagation, we go back one layer at a time and Gradients for weight is product of\n",
    "#     node value feeding into that weight\n",
    "#     slope of loss fun w.r.t node it feeds into\n",
    "#     slope of activation fun at the node it feeds into\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ca3175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backpropagation\n",
    "# use fwd propagation to make prediction\n",
    "# use back propagation to calculate the slope of the loss fun w.r.t each weight\n",
    "# multiply that slope by the learning rate and subtract from the current weights\n",
    "# keep going with that cycle until we get to a flat part \n",
    "\n",
    "\n",
    "# Stochastic gradient descent\n",
    "# for computational efficiency, it's common to calculate slopes on only a subset of the data(a batch)\n",
    "# start over from the beginning once all data is used\n",
    "# each time through the full training data is called epoch (1st, 2nd, 3rd,.. epoch)\n",
    "# when slopes are calulated on one batch at a time rather than on full data : stochastic gradient descent\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de0b787",
   "metadata": {},
   "source": [
    "# Building DL models with keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af52c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras workflow has 4 steps\n",
    "#     specify architecture(no layers, no nodes in layers, activation funs, ..)\n",
    "#     compile(loss function, optimization, ..)\n",
    "#     fit(back propagation and optimization of model weights)\n",
    "#     predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b46de3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "# Model specification\n",
    "predictors = np.loadtxt('hourly_wages.csv', delimiter=',', skiprows=1)[:,1:]\n",
    "n_cols = predictors.shape[1]\n",
    "target = np.loadtxt('hourly_wages.csv', delimiter=',', skiprows=1, usecols=0)\n",
    "\n",
    "print(n_cols)\n",
    "model = Sequential()\n",
    "\n",
    "# first layer\n",
    "model.add(Dense(100, activation='relu',input_shape = (n_cols,)))\n",
    "\n",
    "# second layer\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8e65f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66.7050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216fc139ee0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling model\n",
    "\n",
    "# we can specify optimizer(Usually \"Adam\") and loss function(could be MSE)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "print(\"Loss function: \" + model.loss)\n",
    "\n",
    "# Fitting model\n",
    "\n",
    "# applying backpropagation and gradient descent with your data to update weights\n",
    "# scaling data before fitting can ease optimization\n",
    "#     one common approach - subtract each feature by that features mean and divide it by its standard deviation\n",
    "\n",
    "model.fit(predictors, target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00341622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 594us/step - loss: 1.3334 - accuracy: 0.6285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216fd7ee7c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification Models\n",
    "\n",
    "# we do couple of things differently from regression in DL\n",
    "#     set loss function as categorical_crossentropy(lower score - beeter) instead of mse\n",
    "#         add metrics= accuracy to compile step for easy-to-understand diagnosis\n",
    "#     output layer has separate node for each possible o/come, and uses 'softmax' activation\n",
    "\n",
    "data =  pd.read_csv('titanic_all_numeric.csv')\n",
    "data[\"age_was_missing\"] = data[\"age_was_missing\"].astype(int)\n",
    "predictors =  data.drop(['survived'], axis=1).values\n",
    "target = to_categorical(data['survived'])\n",
    "\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss= 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(predictors, target)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b329d7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "[0.46185616 0.5561937  0.20935412 0.12048928 0.99962246 0.12239509\n",
      " 0.12330358 0.22399366 0.98075897 0.12264533 0.01601755 0.8867909\n",
      " 0.43400422 0.12048616 0.20979638 0.38624415 0.36940596]\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 100)               1100      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,502\n",
      "Trainable params: 21,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Using models\n",
    "#     save, reload and use the model\n",
    "\n",
    "model.save('model_file.h5')\n",
    "my_model = load_model('model_file.h5')\n",
    "\n",
    "data_to_predict_with = predictors[23:40, :]\n",
    "\n",
    "predictions = my_model.predict(data_to_predict_with)\n",
    "probability_true = predictions[:, 1]\n",
    "\n",
    "print(probability_true)\n",
    "# verifying model structure\n",
    "my_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311f2422",
   "metadata": {},
   "source": [
    "# Fine-tuning Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c42965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why optimization is hard\n",
    "\n",
    "# How to to choose architecture and model optimization arguments\n",
    "# optimization of a single weight is hard since we'll be optimizing many weights at once with complex r/ships\n",
    "# updates may not improve model meaningfully\n",
    "# updates too small(if learning rate is low) or too large (if learning rate is high)\n",
    "\n",
    "# Easiest way to see effect of d/t learning rates is to use the simplest optimiser - the stochastic gradient descent(sgd)\n",
    "#     sgd uses fixed learning rate - 0.01 are common\n",
    "#     we can still specify that with lr argument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "364290d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 672us/step - loss: 1.5663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 593us/step - loss: 1.4907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 1ms/step - loss: 1.6738\n"
     ]
    }
   ],
   "source": [
    "input_shape = (n_cols,)\n",
    "\n",
    "def get_new_model(input_shape=input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return(model)\n",
    "\n",
    "lr_to_test = [0.000001, 0.1, 1]\n",
    "\n",
    "for lr in lr_to_test:\n",
    "    model = get_new_model()\n",
    "    my_optimizer = SGD(lr = lr)\n",
    "    model.compile(optimizer = my_optimizer, loss= 'categorical_crossentropy')\n",
    "    model.fit(predictors, target)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e07d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dying neuron problem \n",
    "#     once node starts getting -ve in relu, it'll be 0 even when fed into other neurons\n",
    "\n",
    "# vanishing gradient problem\n",
    "#     occurs when many layers have very small slopes(eg. due to being flat on part of tanh curve)\n",
    "#     In deep networks, updates to backprop were close to 0\n",
    "\n",
    "# The above cases could cause the model not to train better\n",
    "#     the solution could be changing the activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03f13f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 8ms/step - loss: 1.0039 - accuracy: 0.6292 - val_loss: 0.5778 - val_accuracy: 0.6604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21683c19760>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Validation\n",
    "\n",
    "# we use validation data\n",
    "#     data explicitly held out from training, and used onlt to test model performance\n",
    "\n",
    "model.compile(optimizer = my_optimizer, loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(predictors, target, validation_split=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b565fd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.6742 - val_loss: 0.6497 - val_accuracy: 0.6530\n",
      "Epoch 2/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7108 - accuracy: 0.6485 - val_loss: 0.7439 - val_accuracy: 0.6381\n",
      "Epoch 3/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.6645 - val_loss: 0.5993 - val_accuracy: 0.7276\n",
      "Epoch 4/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6645 - val_loss: 0.5788 - val_accuracy: 0.6978\n",
      "Epoch 5/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6822 - val_loss: 0.7218 - val_accuracy: 0.6418\n",
      "Epoch 6/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6152 - accuracy: 0.6838 - val_loss: 0.5342 - val_accuracy: 0.7575\n",
      "Epoch 7/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6774 - val_loss: 0.5576 - val_accuracy: 0.7500\n",
      "Epoch 8/20\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.6838 - val_loss: 0.5587 - val_accuracy: 0.7127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x216839c7a90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# goal is to have best validation score possible so we keep training while validation score is\n",
    "# improving and stop training when the score isn't improving\n",
    "#     we do this with EarlyStopping \n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "model.fit(predictors, target, validation_split=0.3, epochs=20, callbacks=[early_stopping_monitor])\n",
    "\n",
    "\n",
    "# We can experiment with model with\n",
    "#     kd/t architectures, more layers, fewer layers, layers with more nodes, layers with fewer nodes\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ba371fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAx1ElEQVR4nO3deZzV8/7A8de7aVNJUUSlUkqLCiM7CVcp2xUtJ7m2ZLm4uJaLru1ycSdrIdtFKiGJK2vZfqGFViMqSbYKpRQ19f798T5jpunMzJmZ8z3fs7yfj8f3MXO+53vOeZ+W8z6f5f35iKrinHPOlVQt7ACcc86lJk8QzjnnYvIE4ZxzLiZPEM4552LyBOGccy6m6mEHkEiNGjXSli1bhh2Gc86ljVmzZq1S1cax7suoBNGyZUtmzpwZdhjOOZc2ROSr0u7zLibnnHMxeYJwzjkXkycI55xzMXmCcM45F5MnCOecczF5gnDOOReTJwjnnHMxZVQdRGXdfDPssgt06gQdO8IOO4QdkXPOhS/rE8SmTZCXB2vWFJ1r3tySRWHC6NQJ2reHOnXCi9M555It6xNEjRrw00+wbBksWADz5xcdU6bA77/bdSLQuvW2iaNtW6hZM9z34JxzQcj6BAFQrRq0bGlH795F5wsKYPFiSxbFk8dLL8HmzXZN9erQrt22iWOPPSAnJ4x345xziSGZtOVobm6uJmMtpt9/h4ULt00cS5YUXVO7NnTosG3iaN7cWiPOOZcKRGSWqubGus9bEJVQqxZ07mxHcevWQX5+UcJYsADeeguefLLomvr1i5JF8cSx886eOJxzqcVbEEnw889btzQWLIB58+DHH4uuadSoKGkUTx4NGoQWtnMuC3gLImQNG8Khh9pRSBVWrNh6UHzBAnjiCVi7tui6pk23TRzt20Pdusl/H8657OIJIiQiVnuxyy5w1FFF51Xh66+3TRwjRsBvvxU9tlWrbRNH27bW/eWcc4ngCSLFiMDuu9tx3HFF5zdvtkHwkonjlVdsthXYrKm2bbdNHK1b+4wq51zF+RhEmtu4ET7/fNvEsXixtUbAWhXt22+dNDp3thlVzrns5mMQGaxmzaIP/eLWr996RtX8+fDOOzB6dNE1zzwDp52W3Hidc+nDWxBZZvVq+PRT+MtfoEkTePfdsCNyzoWprBaEr+aaZRo0gIMPhsGD4b334KtStyt3zmU7TxBZauBA+zl2bLhxOOdSlyeILLXHHtaSePrpsCNxzqUqTxBZLBKxweu5c8OOxDmXigJNECLSU0QWisgiEbm6lGu6i8hsEVkgIu9EzzUXkakikh89f0mQcWar006z1Wi9FeGciyWwBCEiOcAIoBfQARggIh1KXNMAGAmcoKodgVOjdxUAl6tqe+BA4MKSj3VV16gRHHusjUNs2RJ2NM65VBNkC6IbsEhVl6jqRmAccGKJawYCE1R1GYCqroj+/E5VP47+vhbIB5oGGGvWikRsaY/33gs7EudcqgkyQTQFvi52eznbfsi3BRqKyNsiMktEBpd8EhFpCewDfBTrRURkiIjMFJGZK1euTEzkWeSEE2zhP+9mcs6VFGSCiLW7QcmqvOrAfkBv4FjgehFp+8cTiNQDngcuVdVfYr2Iqo5S1VxVzW3cuHFiIs8idevCySfDs88Wba/qnHMQbIJYDhRf7acZ8G2Ma15V1V9VdRXwLtAFQERqYMnhaVWdEGCcWS8SsQrrV14JOxLnXCoJMkHMAPYUkVYiUhPoD0wqcc2LwGEiUl1E6gAHAPkiIsCjQL6qDg8wRgccfbTtaOfdTM654gJLEKpaAFwEvIYNMo9X1QUiMlREhkavyQdeBeYC04FHVHU+cAhwOtAjOgV2togcF/OFXJVVrw79+sHLL8OaNWFH45xLFb5YnwNg+nQ44AB49FE466ywo3HOJYsv1ufKtf/+0KaNdzM554p4gnCA7WQXicDUqfDNN2FH45xLBZ4g3B8iEduFbty4sCNxzqUCTxDuD3vuaV1N3s3knANPEK6ESAQ++cS2K3XOZTdPEG4r/fpBtWreinDOeYJwJTRpYoVzTz9t4xHOuezlCcJtIxKBpUth2rSwI3HOhckThNvGySfDdtt5N5Nz2c4ThNvG9tvDiSfC+PGwaVPY0TjnwuIJwsUUicCPP8Jrr4UdiXMuLJ4gXEzHHgs77eTdTM5lM08QLqYaNeC00+DFF2Ht2rCjcc6FwROEK1UkAhs2wMSJYUfinAuDJwhXqoMPhpYtvZvJuWzlCcKVSgQGDoQ33oAffgg7GudcsnmCcGWKRGDLFnjmmbAjcc4lmycIV6YOHaBrVxg9OuxInHPJ5gnClSsSgRkz4Isvwo7EOZdMniBcuQYMsPEIH6x2Lrt4gnDlatoUjjzSV3h1LtsEmiBEpKeILBSRRSJydSnXdBeR2SKyQETeqchjXfJEIrBokXU1OeeyQ2AJQkRygBFAL6ADMEBEOpS4pgEwEjhBVTsCp8b7WJdcp5wCtWp5N5Nz2STIFkQ3YJGqLlHVjcA44MQS1wwEJqjqMgBVXVGBx7ok2mEH6NMHxo2DgoKwo3HOJUOQCaIp8HWx28uj54prCzQUkbdFZJaIDK7AY12SRSKwYgW89VbYkTjnkiHIBCExzpUc4qwO7Af0Bo4FrheRtnE+1l5EZIiIzBSRmStXrqxKvK4cxx0HDRp4N5Nz2SLIBLEcaF7sdjPg2xjXvKqqv6rqKuBdoEucjwVAVUepaq6q5jZu3Dhhwbtt1aoFffvCCy/Ar7+GHY1zLmhBJogZwJ4i0kpEagL9gUklrnkROExEqotIHeAAID/Ox7oQRCKwbh1M8r8N5zJeYAlCVQuAi4DXsA/98aq6QESGisjQ6DX5wKvAXGA68Iiqzi/tsUHF6uJ3+OHQrJl3MzmXDUQzqPIpNzdXZ86cGXYYGe/KK+Guu+C776BRo7CjqYBPP4X27a0s3DkHgIjMUtXcWPd5JbWrsEGDbKrr+PFhR1IBkyZBx45w881hR+Jc2vAE4Sqsc2fo1CnNupnuvNN+3nQTTJ8ebizOpQlPEK5SIhGYNg2+/DLsSOIwfTq8/z7ceCPstps1gXwalnPl8gThKmXAAPs5Zky4ccQlL89Kwf/2N3jySVtU6oorwo7KuZTnCcJVSosWcNhhabDC69Kl8NxzcN55sP320L07XH45PPggvPxy2NE5l9I8QbhKi0QgPx9mzw47kjLcfTdUqwZ//WvRuVtusYGUs8+2tUOcczF5gnCVduqpUKNGCg9Wr14Njz4K/ftb8UahWrVsD9XVq+Hcc1O8CeRceMpNECLSVkTeEpH50dudReS64ENzqW7HHaFXLxuH2Lw57GhiGDXKyr4vv3zb+/beG267zaa/Pvpo8mNzLg3E04J4GLgG2ASgqnOxpS+cIxKxgrm33w47khI2boR774UePaBr19jXXHqp3X/ppTZw7ZzbSjwJoo6qlpw47jsCOACOP97GflOum2n8ePjmm9ith0LVqsF//2v9ZKef7htdOFdCPAlilYi0Jrrctoj0Bb4LNCqXNrbbznabe/55+O23sKOJUrWpre3bQ8+eZV/bvDmMHAkffmhdTs65P8STIC4EHgL2EpFvgEuBoUEG5dJLJAK//JJCs0anTrWpVZddZq2E8gwYYMeNN/qm284VU+b/nuje0Oer6tFAY2AvVT1UVb9KSnQuLRx5JOy6awp1M+Xlwc47W8V0vEaMsDfhVdbO/aHMBKGqm7Ed34hu6rM2KVG5tJKTYzNJX3kFfv455GDy8y2Qiy6C2rXjf1zDhvDEE/D55/D3vwcXn3NpJJ4upk9EZJKInC4ify48Ao/MpZVIxCYOPfdcyIEMH24DI+efX/HH9uhh3VIPPGBJxrksV+5+ECLyeIzTqqpnBRNS5fl+EOFRtTHhJk1CnPL6ww+2BsiZZ9qHfGX89ht062YV1vPmgW9j6zJcWftBVC/vwap6ZuJDcplGxFoRw4bB11/b5KCkGznSmjF/+1vln6N2bauy3n9/GDIEJkzwDYZc1oqnkrqZiLwgIitE5AcReV5EmpX3OJd9Bg60n2PHhvDiGzZYgjj+eGjbtmrP1bkz/OtfMHEiPB6rAe1cdohnDOJxYBKwG9AUeCl6zrmttG4NBx5oX8CT7sknYdWqsgvjKuKyy2zl10sugSVLEvOczqWZeBJEY1V9XFULosd/sSmvzm0jErGu+3nzkviiW7bY4HRurq1BngjVqtmsppwcr7J2WSveSupBIpITPQYBPwYdmEtPp51mn6lJrYl4+WWbnnr55YkdL9h9d6uPmDYNbr89cc/rXJqIJ0GcBZwGfI8tsdE3es65bey8Mxx7rK3wumVLkl40L88+zPv2TfxzDxwI/frBDTeAz5BzWabcBKGqy1T1BFVtrKo7q+pJ8VZSi0hPEVkoIotE5OoY93cXkTUiMjt6DCt2399EZIGIzBeRsSJSgaonF6ZIxGYyvf9+El5s5kx4910bK6he7qS8ihOxKbNNmliV9fr1iX8N51JUPLOYnhCRBsVuNxSRx+J4XA4wAugFdAAGiEiHGJe+p6pdo8dN0cc2BS4GclW1E5CDLzGeNk48EerWTVI3U14e1K8P55wT3Gs0bGirvi5cCFdeGdzrOJdi4uli6qyqqwtvqOrPwD5xPK4bsEhVl6jqRmAccGIFYqsObCci1YE6wLcVeKwLUd26cNJJ8OyzVpYQmGXL7EXOPdeSRJCOOsrqK0aMgFdfDfa1nEsR8SSIaiLSsPCGiOxIHAV22JTYr4vdXh49V9JBIjJHRCaLSEcAVf0G+A+wDBv3WKOqr8d6EREZIiIzRWTmypUr4wjLJUMkYusyTZ4c4Ivcc4/9vPjiAF+kmFtvhU6drFJ71arkvKZzIYonQeQB00TkZhG5GZgG3BHH42JNJym5rsfHQAtV7QLcB0wE68bCWhutsPqLutHZU9s+oeooVc1V1dzGvixCyjjmGFulIrBupjVr4OGHbdrU7rsH9CIlFFZZ//QTnHee72XtMl48g9RPAqcAPwArgD+r6lNxPPdyoPiCC80o0U2kqr+o6rro768ANUSkEXA08KWqrlTVTcAE4OA4XtOliOrVbfLPSy/ZZ3nCPfIIrF2buMK4eHXpArfcYktwPPFEcl/buSSLZ5C6NbBYVe8H5gFHFx+0LsMMYE8RaSUiNbFB5kklnruJiE1cF5Fu0Xh+xLqWDhSROtH7jwLy439bLhVEIrb23YQJCX7iTZuse+mII2C//RL85HG47DJ77Ysvhi+/TP7rO5ck8XQxPQ9sFpE2wCNYt8+Y8h6kqgXARcBr2If7eFVdICJDRaRwR7q+wHwRmQPcC/RX8xHwHNYFNS8a56iKvTUXtgMOsOU3Et7N9NxzNo/2iisS/MRxysmx1oOIVVlv3hxOHM4FLJ7lvj9W1X1F5Epgg6reJyKfqGo8M5mSypf7Tj3DhlmPzPLlsNtuCXhCVVtpdd06+PTT+LYUDcro0ZYgbr0VrrkmvDicq4KylvuO53/XJhEZAAwGCncdrpGo4Fxmi0TsM33cuAQ94bvvwqxZ8e83HaRIxAbJhw2Djz8ONxbnAhDP/7AzgYOAf6nqlyLSCghjvU6Xhtq1szX0EtbNlJdn06NOPz1BT1gFhVXWu+xiVdYbNoQdkXMJFc8spk9V9WJVHRu9/aWq/jv40FymiETsC/Znn1XxiRYutGlRF1xg24qmgh13tCrr/Hy46qqwo3EuoUJuo7ts0L+/9QZVuRVx111Qq5YliFRy9NG2FtR998Frr4UdjXMJ4wnCBa5JE1upYsyYKtSWrVxpM4cGD7YlY1PNbbdBhw5WZf2jr4bvMoMnCJcUkYhtzPbhh5V8gpEjrajisssSGlfCbLedNZFWrfIqa5cx4imUaysiD4vI6yIypfBIRnAuc5x8sq1UUalupg0bbJG83r1hr70SHlvCdO0KN98Mzz9vW6A6l+biaUE8ixWsXQf8vdjhXNzq14cTToBnnrFC6AoZPdq6mJK9rEZlXHGFbXv61796lbVLe/EkiAJVfUBVp6vqrMIj8MhcxolErAfm9Zjr8paicL/pffaB7t2DCi1xcnKKWg+DB3uVtUtr8SSIl0TkAhHZVUR2LDwCj8xlnJ49bVZohbqZJk+2+bGJ3m86SC1bwv3325Z6d94ZdjTOVVo8S23Eaierqu4RTEiV50ttpL6hQ+Gpp+CHH6BevTge0KMHfPGFjXDXSKMCflWrsn7xRfjoI2sBOZeCqrTUhqq2inGkXHJw6aFwW+eJE+O4+JNPYOpUWzU1nZIDWGvnwQehUSPrW/Mqa5eG4pnFVENELhaR56LHRSKSZv9bXao4+GBo0SLObqa8PGtmnHtu4HEFYqediqqsr7467Gicq7B4xiAeAPYDRkaP/aLnnKuwatVg4EB44w1YsaKMC5cvtylP55wDDRokK7zE+9OfbEbTvffam3YujcSTIPZX1TNUdUr0OBPYP+jAXOaKRGxyzzPPlHHRvffaDKZLLklaXIG5/XZo3x7+8hfbrtS5NBFPgtgc3VUOABHZA/C5e67SOna0nTtL7WZauxZGjYJTT7UZQeluu+2slmPFChul9yprlybiSRB/B6aKyNsi8g4wBUiDiiWXyiIRm9yzaFGMOx991DayTofCuHjtuy/cdBM8+6wlC+fSQLnTXAFEpBbQDhDgM1X9PejAKsOnuaaP5cth993hn/+04w8FBdCmjd357ruhxReIzZut2G/uXDtatAg7IucqN81VRHpEf/4Z6A20AVoDvaPnnKu0Zs3giCOsm2mr7ygTJsBXX2VW66FQYZW1qldZu7RQVhfTEdGfx8c4+gQcl8sCkYjVwP3R6FOF//wH9twTjj8+1NgC06qVDcC/+65N43UuhVUv7Q5VLWz436SqW1VTR7cdda5K+vaFCy+0VsT++2NLU8yYYUt7h73fdJDOOMN2xrvuOpsG27Vr2BE5F1M8/wufj3HuuXieXER6ishCEVkkIttUColIdxFZIyKzo8ewYvc1iBbmfSYi+SJyUDyv6dJHgwbQpw+MG2dDD+TlWXHZGWeEHVqwROChh+y9Dhpk+1w4l4LKGoPYS0ROAXYQkT8XO/4C1C7viUUkBxgB9AI6AANEpEOMS99T1a7R46Zi5+8BXlXVvYAuQH78b8uli0jE1mWa8tQ3MGkSnH8+1KkTdljBa9QIHn8cFiyAa64JOxrnYiqrBdEOG2towNbjD/sC8ax90A1YpKpLVHUjMA44MZ6gRKQ+cDjwKICqblTV1fE81qWX446DHXaAp//9ta23dOGFYYeUPD172vu9+254882wo3FuG6UmCFV9MVo13UdVzyx2XKyq0+J47qbA18VuL4+eK+kgEZkjIpNFpGP03B7ASuBxEflERB4RkbqxXkREhojITBGZuXLlyjjCcqmkdm3o2+c3JnzekfX9z7INrLPJHXfYLnleZe1SUDxjEJ+IyIUiMlJEHis84nhcrMX7SxZdfAy0UNUuwH3AxOj56lhL5QFV3Qf4FYi52pmqjlLVXFXNbdy4cRxhuVQTqfks69iel/b+R9ihJF+dOlY498MPcMEFXmXtUko8CeIpoAlwLPAO0AxYG8fjlgPNi91uBnxb/AJV/UVV10V/fwWoISKNoo9drqofRS99DksYLtP89htH/O9KmtZaxdPvNi//+ky0335w4422ONWYMWFH49wf4kkQbVT1euBXVX0CK5rbO47HzQD2FJFWIlIT6A9MKn6BiDQRsW3CRKRbNJ4fVfV74GsRaRe99Cjg07jekUsvY8ZQbcX3DDhhHZMn25akWemqq+CQQ2xMYtmysKNxDogvQRRuMb9aRDoBOwAty3uQqhYAFwGvYTOQxqvqAhEZKiJDo5f1BeaLyBzgXqC/Fq398VfgaRGZC3QFbo3vLbm0oWr7TXfuTOSaFhQU2FJFWSknx7ba27zZpvlu2RJ2RM7FteXoOVgtRGfgcaAeMExVHww+vIrxtZjSzKuvQq9e8MQT6OmD6dQJGja0erms9fjjcNZZtpf1FVeEHY3LAmWtxRTXYn3pwhNEmjnmGPj0U/jyS6hZk1tvhWuvtZuZsMp3pajCKafA//5nVeWdO4cdkctwZSWIUpfaEJHLynpSVR1e1cBcFpszx+b+//vfULMmYDvNXXutjdP+IwsnNAFWZT1qFOy9t1URzphhc4GdC0FZYxDbR49c4HyshqEpMBSrjHau8oYPh7p1YciQP061bAmHHhpjhdds06gRPPYYzJ9vGdO5kJRVKHejqt4INAL2VdXLVfVybE/qZskK0GWgb76BsWPh7LNt0KGYSMR6nebMCSm2VNGrl9VFDB8Ob70VdjQuS8Uzi2l3YGOx2xuJYxaTc6W67z6brXPppdvcdeqpUL16GduRZpM774R27WxW088/hx2Ny0LxFspNF5EbROSfwEfAk8GG5TLWunW2kumf/2x7I5Sw00725XnsWN9PZ5sqa+eSrNwEoar/As4EfgZWA2eqqtckuMp57DFYvbrMHeMiEeuFyrQdRyslN9f2ZB03zqusXdKVOs1VROqr6i8ismOs+1U15VYW82muKW7zZtstbtdd4f/+r9TL1q+HXXaBfv3gkUeSGF+qKiiAww+3wZm5c22/bucSpFJ7UgOFX1dmATOLHYW3nauYF16wIody9puuU8d6oJ591vfSAWxQprDK+i9/8SprlzRlzWLqE/3ZSlX3KHa0UtU9kheiyxh5edC6NZxY/rYgkQj88ovViznsz+3uu2HqVLjrrrCjcVmirEK5MldPVdWPEx+Oy1jTpsGHH9oMppycci/v0cO6mZ5+2gqLHbYEx8svWxXhMcd4lbULXKkJAsgr4z4FeiQ4FpfJ8vKs5uHMM+O6vHp16N8fHnjAZniWKJfITsWrrAcNgunTvcraBaqsLqYjyzg8Obj4LV5s4w9Dh1r1dJwGDYKNG+H55wOMLd00bgyPPgrz5sF114Udjctw8dRBICKdROQ0ERlceAQdmMsgd99tTYKLLqrQw/bbD9q29aK5bfTubcl2+HAbk3AuIOUmiGhx3H3R40jgDuCEgONymeKnn6z2YeBA2G23Cj1UxAar33kHli8PKL509Z//QJs2VmW9enXY0bgMFU8Loi+2o9v3qnom0AWoFWhULnM89JAVNlxW5uLApRo40BbuGzs2wXGlu7p1rcr6229tFzrnAhBPgtigqluAAhGpD6wAfJqrK9/GjTZrqQozbtq0gQMO8G6mmLp1g2HDrMJ63Liwo3EZKJ4EMVNEGgAPY0VyHwPTgwzKZYixY+G778otjCtPJGKru86fn6C4Msk//gEHHgjnnw9ffx12NC7DlJogROR+ETlYVS9Q1dXRLUaPAc6IdjU5VzpVm9raqRP86U9Veqp+/ax0wlsRMRRWWW/a5FXWLuHKakF8AeSJyFIRuV1EuqrqUlWdm6zgXBp74w2binn55TbaXAU772y9VGPG+OdfTG3aWHX1lClwzz1hR+MySFl1EPeo6kHAEcBPwOMiki8iw0SkbdIidOkpLw+aNIEBAxLydJEILFtW5hp/2e2cc+CEE+Caa7wvziVMPMt9f6Wqt6vqPsBA4GQgP54nF5GeIrJQRBaJyNUx7u8uImtEZHb0GFbi/hwR+UREXo7z/bhUMG8evP46/PWvUCsxE95OOskW8fNuplKIwMMPww47WDb9/fewI3IZIJ46iBoicryIPA1MBj4Hyl0dR0RygBFAL2wP6wEiEmsv6/dUtWv0uKnEfZcQZzJyKWT4cPs0Hzo0YU9Zr56t8ffsszY5ysWw885WZT13Llx/fdjRuAxQ1iD1MSLyGLAcGAK8ArRW1X6qOjGO5+4GLFLVJaq6ERgHlL+MZ9HrNwN6A74jQDr57jv7mn/mmbBjzK1EKm3QIKu7e/XVhD5tZunTB4YMsUK6d94JOxqX5spqQfwD+ABor6rHq+rTqvprBZ67KVB83t3y6LmSDhKROSIyWUQ6Fjt/N3AlUOawpIgMEZGZIjJz5cqVFQjPBeL++22Dmxj7TVfVMcdAo0bezVSuwmXVBw+GNWvCjsalsfIW63u4CjvHxZq6UnL7uo+BFqraBVvKYyKAiPQBVqjqrPJeRFVHqWququY2bty4kqG6hPj1V1t+9aSTbGZNgtWoYVNeJ02yvSJcKerVsyrrb76p8PpXzhUX12J9lbQcaF7sdjPg2+IXqOovqrou+vsrQA0RaQQcApwgIkuxrqkeIjI6wFhdIvz3v7Y2dxUL48oSidgucy+8ENhLZIYDDrDVXkePhg8+CDsal6ZK3ZO6yk8sUh0b0D4K+AaYAQxU1QXFrmkC/KCqKiLdgOewFoUWu6Y7cEXhDndl8T2pQ7R5M7RrZ31AH3xQ5dqH0qha46R1a5so5cpQUGD1KL16hR2JS2GV3ZO6SlS1ALgIeA2biTReVReIyFARKZze0heYLyJzgHuB/hpUxnLBmjTJ9n1IQGFcWURsAb+33rLxcFeG6tU9ObgqCawFEQZvQYTo0EOtz/uLL+yDKUCffQbt29ts2r/9LdCXci7jhdKCcFnko4+sxPnSSwNPDgB77QX77uuzmZwLmicIV3V5eVbBe9ZZSXvJSARmzYKFC5P2ks5lHU8Qrmq+/NI2jT7vPNh++6S9bP/+Nh7hrQjnguMJwlXNPfdAtWq27lIS7bYbHHWUJYgMGkZzLqV4gnCV9/PP8Mgj9nW+WbOkv3wkAkuW2BCIcy7xPEG4yhs1yqqnAyyMK8uf/wy1a3s3k3NB8QThKmfjRrj3Xuvn6do1lBDq14fjj4dnnrEN1ZxzieUJwlXOM8/At9+G1nooFInAypXw5puhhuFcRvIE4SqucL/pDh2gZ89QQ+nVCxo2tCWHnHOJ5QnCVdyUKTBnDlx2WaDLasSjZk049VSYOBHWrQs1FOcyjicIgNtvhxkzwo4ifeTl2e5lkUjYkQAWxvr18OKLYUfiXGbxBLF6Ndx1F3TrZqvALV0adkSp7dNPYfJk22egdu2wowFsGajmzX02k3OJ5gmiQQP4/HO49lrbZKBdO/j7322Ov9vW8OGw3XZw/vlhR/KHatUst7/+OqxYEXY0zmUOTxBg8yVvucVWIh04sGjLxrvugt9/Dzu61PHDD/DUU3DGGbbvQwqJRGxLivHjw47EuczhCaK4Zs3g8cfhk09g//1tELZDB/vU8fUcYMQIKzhIwTW2994bOnf2bibnEskTRCxdusBrr8Grr0LdurYR8kEHwfvvhx1ZeNavh5EjrTKtbduwo4kpEoEPP7R9i5zLJJs32yy9FSvgq69sT5RPPoFp02zzrLfeCuZ1g1+8P50deywcfTQ88QRcfz0cdhicfDL8+98p+yEZmCefhB9/DL0wriwDBsDVV8OYMfbX5VxQNm+GDRuKjvXrt74dz30VeUx5KwXssgt8/33i36fvKBevX3+1MYnbb4fffrPlrf/5T2jcOJjXSyVbttgWbvXrw/Tpodc+lKV7d/uPkp+f0mG6gKjaxoa//pq4D+dY5yu7tEu1ajbHo+RRp07s82XdV/x8vXqwzz6Vi6msHeW8BRGvunXhuuvg3HPhhhvgwQftW/U119hOatttF3aEwXn5ZZvpNXZsyn/qRiIwZIhtJpQb85+8y1TvvmsTEKdPj/8xImV/GNevH/+HdDzna9ZM+f9CW/EWRGV99hlcdRVMmmSD2//6FwwaZF8RMs3hh1vH5+LFSdlStCp+/hmaNIELLrAGn8t8+fnWtThpEjRtanModt01vm/l6faBHYSyWhCoasYc++23nybd22+r5uaqgmrXrqpvvJH8GII0fbq9t7y8sCOJ20knqTZpolpQEHYkLkjffqt67rmq1aqp1q+vetttqr/+GnZU6QeYqaV8pgb6dVdEeorIQhFZJCJXx7i/u4isEZHZ0WNY9HxzEZkqIvkiskBELgkyzio54gjbsWbMGPv6eswxcNxxMH9+2JElRl6etbPPOSfsSOIWidg4xJQpYUfigrB2LQwbBm3awH//a5sZLl5srYg6dcKOLsOUljmqegA5wGJgD6AmMAfoUOKa7sDLMR67K7Bv9Pftgc9LPjbWEUoLorgNG1TvvFO1QQP7WnP22arffBNuTFWxdKlqTo7qFVeEHUmFbNhg3yjPOCPsSFwibdyoOmKE6s47W6O2Xz/VRYvCjir9EVILohuwSFWXqOpGYBxwYjwPVNXvVPXj6O9rgXygaWCRJkrt2nDFFbBoEVxyiQ1i77mnzXZKx6VG77nHOmgvvjjsSCqkdm045RSYMMFmnLj0pmp/lx07woUXwl57WaN93Dhb8MAFJ8gE0RT4utjt5cT+kD9IROaIyGQR6VjyThFpCewDxNx5WESGiMhMEZm5cuXKBISdADvtZGsW5edDnz5w003WHh41CgoKwo4uPmvW2H7Tp51mK+GlmUGDrCvipZfCjsRVxf/9HxxyiCX8GjXs7/Ptt21tTRe8IBNErLkBJadMfQy0UNUuwH3AxK2eQKQe8Dxwqar+EutFVHWUquaqam7jVKtJaN3adl774ANLEOedZ+tBvPxy6i/d8fDD9gmbwoVxZTniCNhtN196I10tXGh7jh96qC2w/PDDtgVJnz4+6yiZgkwQy4HiXz2bAd8Wv0BVf1HVddHfXwFqiEgjABGpgSWHp1V1QoBxBu/AA+G996ydXFBgy1X06GGT9VPRpk3WvdS9O+y7b9jRVEpOjlVWT54MP/0UdjQuXj/8YFOUO3aEN96Am2+2NTTPOSflZ1hnpCATxAxgTxFpJSI1gf7ApOIXiEgTEfs+ICLdovH8GD33KJCvqsMDjDF5RGyZjgUL4P77bZZTbq71hXz1VdjRbe3ZZ2H58rRtPRSKRCzXPfts2JG48qxbZz2xrVtba2HoUJuZdN11VqPqQlLa6HUiDuA4bAbSYuDa6LmhwNDo7xcBC7AZTh8CB0fPH4p1R80FZkeP48p7vdBnMVXE6tWq11yjWru2aq1aqldeqfrzz2FHpbpli+q++6q2a6e6eXPY0VTJli2q7durHnZY2JG40mzapPrgg1a3Aqp9+6p+/nnYUWUXypjFFGphW6KPtEoQhZYtUx08WFVEdaedVO++W/X338OLZ+pU+2fx0EPhxZBAt9xib2fp0rAjccVt2aI6caLqXnvZ388hh6hOmxZ2VNmprASRgetCpJnmzW212FmzoGtXW9epQwd47rlwBrLz8mwBwtNPT/5rB2DgQPs5Zky4cbgiH35oq7ecdJL9E5840YboDjoo7MhcSZ4gUsU++9io3Cuv2CIxp55q8/umTUteDJ99ZjOsLrggYxYfbNUKDj7YZjOl+sSxTPfFF/bP+qCD7PcHH7ShuBNP9JlJqcoTRCoRgV69YPZsq0FYutSSRN++VnwXtLvuglq1LEFkkEjE5gbMnRt2JNlpxQpbDqNDB5tVdsMN9s/5vPN8ZlKq8wSRinJy4Oyz7WvWjTfaznbt21t19qpVwbzmihVW+T14MOy8czCvEZLTTrMPIq+JSK71622R4zZt4IEHbKX8RYtsYYF69cKOzsXDE0Qqq1vXViVbtAjOOsumx7ZubZsWJXoNiZEjbSOkyy5L7POmgEaNbHPAsWNt7yMXrIICePRRW2XmuuvgqKOsK2nkSFuK3aUPTxDpoEkTeOghmDfPRveuvhratYPRoxPzibdhA4wYAb1720I3GWjQICvt6NYNrr0Wpk6F338PO6rMogr/+5/NtTjnHGjRwrZxf+GFjP1nlfE8QaSTDh1sMZopU4pmGu2/f9XXtX7qKeu6SvPCuLKceqptJV67tjXAevSAhg2tZXHnnbYBvLcuKm/GDDjySFsKY+NGeP75onWUXPryHeXS1ZYt1mfyj3/AsmX27f+OOyyJVPR5OnSwhfRnzcqK6SS//GLbU775ph0LFtj5nXay7pCjj7ajVatw40wHixdbi+yZZ+w7yw032FhDjRphR+bi5TvKZbING1TvuEN1hx1sD4pzz7WttuL10ktWqTR6dGAhprpvvlF96inbP2K33eyPA1T32EN1yBDV8eNVV60KO8rUsnKl6iWXqNaooVqnjur116uuWRN2VK4yKKNQzlsQmWLVKrjlFhtLqFXLdm+//PLyp4sceaQNgi9Z4l/7sNSwcKGVpLz5po1VrF1rDat99y1qXRxySMaUilTIhg22juNtt9n6SWefba2G3XYLOzJXWd6CyCZffGEL2oAtcDNqlC14E8usWXbdnXcmN8Y0smmTLQFx002qhx9u35jBls866ijbB3nGjMzf/7qgQPXxx1WbNbP3f/zxqgsWhB2VSwS8BZGFPvjAdrebNs3WTr7jDivCKz7GEInYoPfXX8MOO4QXaxpZt86WhSgcvygsvmvY0Aa+C1sYrVtnxnCOKrz2Glx5pU2i239/G9Q/4oiwI3OJUlYLwmcxZaqDDrI5hs89Z/M5e/eGY46x6TpgSeGZZ2w+oieHuNWrZ3k2L882sPn+e1vn6eSTYfp0OP98m//fqpX90Y4bZzWI6ejjj+2fTK9eVvQ2frxt9enJIXt4CyIbbNxoC9/cdJPtnjNokFVrP/WUTUNp0SLsCDOCqg3nFLYupkyB1avtvi5diloXhx2W2nscLF1qM5PGjLEiw2HDbFmMmjXDjswFoawWhCeIbLJ6tRUD3H23tSr69bOvuC4Qmzfbt/DChPH++5ara9SwBQQLE0ZubmqsSfTTT7Y0xv33Q7VqVlR/5ZXewMx0niDc1r76CkaNsj4Qn+yfNOvXW/HYm2/aLKnC3r769W0yWWHCaNcuueMXv/0G990Ht94Ka9bAmWfaEmDNmiUvBhceTxDOpaBVq6wbqjBhLF1q55s1K0oWRx0V3PpFW7bYAobXXWe1lscdZw3MvfcO5vVcavIE4VwaWLKkqDvqrbesywegU6eihHH44bD99lV/rTfesO6j2bNhv/1skluPHlV/Xpd+PEE4l2a2bLEP78KE8d571hVUvToceGBRwujWrWL1jbNnw1VXweuvQ8uW1q3Ur5+NObjs5AnCuTT3229W0lKYMGbOtFlT9epB9+5FCaNDh9jjF8uWwfXX28S1hg2tW+mCC6zo3mU3TxDOZZiffoK33y5aEqRww8EmTbYev6hXz5bFuOceu//SS221+AYNQgrcpZzQEoSI9ATuAXKAR1T13yXu7w68CHwZPTVBVW+K57GxeIJw2WrpUhu3KBy/WLnSzteqZVNrBw+2Mpjddw81TJeCQkkQIpIDfA4cAywHZgADVPXTYtd0B65Q1T4VfWwsniCcs/GLefMsWSxebEVuXbqEHZVLVWUliCDLc7oBi1R1STSIccCJQJkf8gl4rHNZrVo1SwieFFxVBTl3oSnwdbHby6PnSjpIROaIyGQR6VjBxzrnnAtIkC2IWLWgJfuzPgZaqOo6ETkOmAjsGedj7UVEhgBDAHb3DlbnnEuYIFsQy4HmxW43A74tfoGq/qKq66K/vwLUEJFG8Ty22HOMUtVcVc1t3LhxIuN3zrmsFmSCmAHsKSKtRKQm0B+YVPwCEWkiYrO2RaRbNJ4f43msc865YAXWxaSqBSJyEfAaNlX1MVVdICJDo/c/CPQFzheRAmAD0D+6w1HMxwYVq3POuW15oZxzzmUx31HOOedchXmCcM45F1NGdTGJyErgq0o+vBGwKoHhpAN/z5kv294v+HuuqBaqGnMKaEYliKoQkZml9cNlKn/PmS/b3i/4e04k72JyzjkXkycI55xzMXmCKDIq7ABC4O8582Xb+wV/zwnjYxDOOedi8haEc865mDxBOOeciynrE4SI9BSRhSKySESuDjueZBCRx0RkhYjMDzuWZBCR5iIyVUTyRWSBiFwSdkxBE5HaIjI9utfKAhG5MeyYkkVEckTkExF5OexYkkFElorIPBGZLSIJXWsoq8cgKru1aboTkcOBdcCTqtop7HiCJiK7Aruq6scisj0wCzgpk/+eo6sk143utVIDeB+4RFU/DDm0wInIZUAuUL/kdsaZSESWArmqmvDiwGxvQfyxtamqbgQKtzbNaKr6LvBT2HEki6p+p6ofR39fC+ST4TsUqlkXvVkjemT8t0ERaQb0Bh4JO5ZMkO0Jwrc2zTIi0hLYB/go5FACF+1qmQ2sAN5Q1Yx/z8DdwJXAlpDjSCYFXheRWdEdNhMm2xNE3FubuvQnIvWA54FLVfWXsOMJmqpuVtWu2I6M3UQko7sTRaQPsEJVZ4UdS5Idoqr7Ar2AC6NdyAmR7Qki7q1NXXqL9sM/DzytqhPCjieZVHU18DbQM9xIAncIcEK0T34c0ENERocbUvBU9dvozxXAC1jXeUJke4LwrU2zQHTA9lEgX1WHhx1PMohIYxFpEP19O+Bo4LNQgwqYql6jqs1UtSX2f3mKqg4KOaxAiUjd6MQLRKQu8CcgYbMTszpBqGoBULi1aT4wPhu2NhWRscAHQDsRWS4iZ4cdU8AOAU7HvlHOjh7HhR1UwHYFporIXOyL0BuqmhXTPrPMLsD7IjIHmA78T1VfTdSTZ/U0V+ecc6XL6haEc8650nmCcM45F5MnCOecczF5gnDOOReTJwjnnHMxeYJwrhwisrnY9NjZiVz1V0RaZsuqui79VA87AOfSwIbokhXOZRVvQThXSdF1+G+P7rswXUTaRM+3EJG3RGRu9Ofu0fO7iMgL0T0a5ojIwdGnyhGRh6P7NrwerXxGRC4WkU+jzzMupLfpspgnCOfKt12JLqZ+xe77RVW7AfdjK4kS/f1JVe0MPA3cGz1/L/COqnYB9gUKq/b3BEaoakdgNXBK9PzVwD7R5xkazFtzrnReSe1cOURknarWi3F+KdBDVZdEFwP8XlV3EpFV2AZFm6Lnv1PVRiKyEmimqr8Xe46W2DIYe0ZvXwXUUNVbRORVbGOnicDEYvs7OJcU3oJwrmq0lN9LuyaW34v9vpmiscHewAhgP2CWiPiYoUsqTxDOVU2/Yj8/iP4+DVtNFCCCbfcJ8BZwPvyxmU/90p5URKoBzVV1KrYBTgNgm1aMc0HybyTOlW+76M5shV5V1cKprrVE5CPsy9aA6LmLgcdE5O/ASuDM6PlLgFHR1XM3Y8niu1JeMwcYLSI7YBtb3RXd18G5pPExCOcqKcjN4p1LBd7F5JxzLiZvQTjnnIvJWxDOOedi8gThnHMuJk8QzjnnYvIE4ZxzLiZPEM4552L6f0x9gXJlV5wzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exp'ting with wider networks\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100,activation='relu'))\n",
    "\n",
    "model_2.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8536bb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exp'menting with more layers\n",
    "\n",
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(10, activation ='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(10, activation ='relu'))\n",
    "model_2.add(Dense(10, activation ='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation ='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model.fit(predictors, target, epochs=15, validation_split=0.4, verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.4, verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec5df64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Capacity\n",
    "\n",
    "# Considerations to think about when deciding what models to try\n",
    "# Model/ Network Capacity\n",
    "#     closely related to terms overfitting and underfitting\n",
    "#     model capacity is model's ability to capture predictive patterns in our data\n",
    "#         larger layers, wider networks cause this\n",
    "\n",
    "# start with small network\n",
    "# gradually increase capacity\n",
    "# keep increasing capacity until validation score is no longer improving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ff64c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Recognizing hadwritten digits\n",
    "\n",
    "# 28 x 28 grid flattened to 784 values for each image\n",
    "# Value in each part of array denotes darkness of that pixel\n",
    "\n",
    "# taking the 784 features for each image as i/p and predicting  digits from among 10 possible values\n",
    "\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "X = train_X[:1000].reshape(1000,28,28)\n",
    "y = train_y[:1000].reshape(1000)\n",
    "print(str(X.shape))\n",
    "# print(str(train_X.shape))\n",
    "# print(str(train_y.shape))\n",
    "\n",
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# input_shape=(x_train.shape[1],)\n",
    "\n",
    "#\n",
    "# model.add(Dense(50, activation = 'relu', input_shape = (784,)))\n",
    "model.add(Dense(50, activation = 'relu', input_shape = (X.shape[1],)))\n",
    "\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "# model.fit(X, y, validation_split = 0.3, epochs=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059e7f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
